import torch
import numpy as np
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

class StoryboardNode:
    """
    Node ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏£‡∏¥‡∏°
    """
    CATEGORY = "Storyboard"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "label": ("STRING", {"default": "Scene 1", "multiline": False}),
                "action": ("STRING", {"default": "", "multiline": True}),
                "camera": ("STRING", {"default": "", "multiline": True}),
                "notes": ("STRING", {"default": "", "multiline": True}),
                "mood": ("STRING", {"default": "", "multiline": True}),
                "dialogue": ("STRING", {"default": "", "multiline": True}),
                "details": ("STRING", {"default": "", "multiline": True}),
                "extra_text": ("STRING", {"default": "", "multiline": True}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("caption",)
    FUNCTION = "generate_caption"
    OUTPUT_NODE = True

    def __init__(self):
        self.processor = None
        self.model = None

    def _load_model(self):
        if self.processor is None or self.model is None:
            self.processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
            self.model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
            self.model = self.model.to("cuda" if torch.cuda.is_available() else "cpu")

    def generate_caption(
        self,
        image,
        label,
        action,
        camera,
        notes,
        mood,
        dialogue,
        details,
        extra_text,
    ):
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î
        self._load_model()

        # ‡πÅ‡∏õ‡∏•‡∏á image ‡πÄ‡∏õ‡πá‡∏ô PIL Image ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ shape
        if isinstance(image, Image.Image):
            pil_image = image.convert("RGB")
        else:
            # ‡πÄ‡∏õ‡πá‡∏ô Tensor ‡∏´‡∏£‡∏∑‡∏≠ array
            if isinstance(image, torch.Tensor):
                arr = image.cpu().numpy()
            elif isinstance(image, np.ndarray):
                arr = image
            else:
                arr = np.array(image)

            # ‡∏•‡∏î‡∏°‡∏¥‡∏ï‡∏¥‡∏à‡∏≤‡∏Å batch/frame ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            while arr.ndim > 3 and arr.shape[0] == 1:
                arr = arr[0]

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö HWC ‡∏´‡∏£‡∏∑‡∏≠ CHW
            if arr.ndim == 3 and arr.shape[2] == 3:
                pass
            elif arr.ndim == 3 and arr.shape[0] == 3:
                arr = np.transpose(arr, (1, 2, 0))
            else:
                raise TypeError(f"Unsupported image shape: {arr.shape}")

            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô 0-255 uint8
            arr = (arr * 255).clip(0, 255).astype("uint8")
            pil_image = Image.fromarray(arr).convert("RGB")

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á caption ‡∏à‡∏≤‡∏Å BLIP
        inputs = self.processor(pil_image, return_tensors="pt")
        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
        out = self.model.generate(**inputs)
        caption = self.processor.decode(out[0], skip_special_tokens=True)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÄ‡∏ï‡πá‡∏°
        parts = []
        if extra_text:
            parts.append(f"Extra Text: {extra_text}")
        parts.extend([
            f"Label: {label}",
            f"Caption: {caption}",
            f"Action: {action}",
            f"Camera: {camera}",
            f"Notes: {notes}",
            f"Mood: {mood}",
            f"Dialogue: {dialogue}",
            f"Details: {details}",
        ])
        full_prompt = "\n".join(parts)
        return (full_prompt,)

# ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡∏î‡∏π‡∏•
print("üì¶ storyboard_node module loaded")
NODE_CLASS_MAPPINGS = {"StoryboardNode": StoryboardNode}
NODE_DISPLAY_NAME_MAPPINGS = {"StoryboardNode": "üé¨ Storyboard Image ‚Üí Prompt"}
print("‚úÖ NODE_CLASS_MAPPINGS defined")
